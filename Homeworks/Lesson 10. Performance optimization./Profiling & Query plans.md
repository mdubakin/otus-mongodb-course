# Profiling & Query plans.

### Table of contents:
  - [Задание.](#задание)
  - [Выполнение.](#выполнение)
   

# Задание.
```
[x] Изучить и поработать с профайлингом в MongoDB.
[x] Описать струтуру документа профилирования.
[] Изучить что такое query plans и как их использовать для траблшутинга медленных запросов.
```
# Выполнение.
## Profiling.

### Настройка profiling:
1. 3 уровня профайлинга:
   1. 0 - профайлинг выключен.
   2. 1 - профайлинг только запросов, медленее чем указано в slowms.
   3. 2 - профайлинг всех запросов.
2. `slowms` - запросы дольше этого значения будут считатся медленными.
3. `sampleRate` - доля профайлинга медленных запросов. Пример: 1 - все запросы, 0.5 - половина запросов, 0.1 - десятая часть запросов.

### Profiling настраивается:
1. на уровне базы данных:
   1. Проверить статус профайлинга: `db.getProfilingStatus()`
   2. Изменить уровень профайлинга для одной базы данных: 
      1. `db.setProfilingLevel(1, {"slowms": 50, "sampleRate": 0.5})`; 
      2. `db.setProfilingLevel(1, {"slowms": 100, "sampleRate": Double("1")})`
2. на уровне MongoDB для всех баз данных:
   1. С помощью ключа при запуске: `mongod --profile 1 --slowms 50 --slowOpSampleRate 0.5`
   2. С помощью директивы в конфигурационном файле: 
      ```yaml
      operationProfiling:
        mode: 1
        slowOpThresholdMs: 50
        slowOpSampleRate: 0.5
      ```

### Структура документов в system.profile.

Все записи профайлера представляют собой обычные документы со следующим набором основных полей:

* `op` - тип операции(insert, query, update, remove, getmore, command)
* `ns` - коллекция(а точнее namespace), над которой производится операция
* `millis` - время выполнения операции в миллисекундах
* `ts` - время(timestamp) операции. Большого значения это не имеет, но это дата окончания выполнения операции.
* `client` - IP-адрес или имя хоста, с которого была отправлена команда
* `user` - авторизованный пользователь, который выполнил запрос. Если вы не используете авторизацию, то в профайлер будет записана пустая строка.

### Увеличиваем размер system.profile.

В прошлой части я упоминал, что данная коллекция имеет ограничение в 1Мб. Это значение можно изменить, если вам нужен больший объем лога. Сделать это можно следующим образом: так как system.profile является ограниченной коллекцией, мы не можем изменить размер зарезервированного под неё места, но мы можем пересоздать её с другими опциями. Вот пример консольных команд:
```js
  db.setProfilingLevel(0)    // останавливаем профилирование
  db.system.profile.drop()   // удаляем коллекцию
  // создаем ограниченную коллекцию с нужными параметрами
  db.createCollection( "system.profile", { "capped": true, "size": 4194304 } )   
  db.setProfilingLevel(1)    // включаем профилирование назад
```
`size` в данном случае это размер в байтах.

### Запросы к профайлеру.

К коллекции system.profile применимы все те же способы формирования запросов, что и к обычной коллекции. Вот несколько самых ходовых вариантов:
```js
  // Вывести все данные в порядке убывания даты создания
  db.system.profile.find().sort({$natural:-1});
          
  // Найти все операции длиннее 5 мс.
  db.system.profile.find( { millis : { $gt : 5 } } );
          
  // Вывести все данные в порядке убывания времени выполнения
  // (самые тяжелые запросы в начале)
  db.system.profile.find().sort({millis:-1});
```

### Продвинутые запросы.

На стадии поддержки гораздо важнее видеть общую картину, чем анализировать отдельные запросы. Например, можно следить за количеством “проблемных” запросов(count) в определенный день и средним временем выполнения(avg_ms):
```js
> db.system.profile.aggregate([{$match: {ts:{$gte:ISODate("2022-01-01T00:00:00.000Z"), $lt:ISODate("2022-01-05T00:00:00.000Z")}}}, {$group:{_id:null, count:{$sum:1}, avg_ms:{$avg:'$millis'}}}])

// result
{
        "result" : [
                {
                        "_id" : null,
                        "count" : 953,
                        "avg_ms" : 141.8058761804827
                }
        ],
        "ok" : 1
}
```

Сгруппируем по типам операций и добавим еще пару метрик:
```js
> db.system.profile.aggregate([{$match: {ts:{$gte:ISODate("2013-06-29T00:00:00.000Z"), $lt:ISODate("2013-06-30T00:00:00.000Z")}}}, {$group:{_id:'$op', count:{$sum:1}, avg_ms:{$avg:'$millis'}, min_ms:{$min:'$millis'}, max_ms:{$max:'$millis'}}}])

// result
{
        "result" : [
                {
                        "_id" : "update",
                        "count" : 4,
                        "avg_ms" : 124,
                        "min_ms" : 111,
                        "max_ms" : 138
                },
                {
                        "_id" : "command",
                        "count" : 15,
                        "avg_ms" : 372.8,
                        "min_ms" : 212,
                        "max_ms" : 3582
                },
                {
                        "_id" : "insert",
                        "count" : 868,
                        "avg_ms" : 115.67396313364054,
                        "min_ms" : 100,
                        "max_ms" : 308
                }
        ],
        "ok" : 1
}
```

Вот это уже интересней, глядя на этот результат можно сделать ряд выводов:
* основную часть времени база делает insert и время выполнения находится в пределах нормы
* update происходят редко и не вызывают осложнений
* command тоже происходит редко, но среди них есть тяжелые запросы.

К сожалению, command это не какая-то конкретная операция, поэтому, в данном случае, придется вернуться к прошлой технике запросов:
```js
> db.system.profile.find({op:'command'}).sort({millis:-1}).pretty()
...
```

Можно сгруппировать данные по коллекции:
```js
> db.system.profile.aggregate([{$match: {ts:{$gte:ISODate("2013-06-29T00:00:00.000Z"), $lt:ISODate("2013-06-30T00:00:00.000Z")}}}, {$group:{_id:'$ns', count:{$sum:1}, avg_ms:{$avg:'$millis'}, min_ms:{$min:'$millis'}, max_ms:{$max:'$millis'}}}])

// result
{
	"result" : [
		{
			"_id" : "test_db.media",
			"count" : 10,
			"avg_ms" : 125.2,
			"min_ms" : 110,
			"max_ms" : 143
		},
		{
			"_id" : "test_db.price",
			"count" : 62,
			"avg_ms" : 129.67741935483872,
			"min_ms" : 100,
			"max_ms" : 262
		},
		{
			"_id" : "test_db.$cmd",
			"count" : 114,
			"avg_ms" : 1034.587719298245,
			"min_ms" : 149,
			"max_ms" : 4741
		},
		{
			"_id" : "test_db.events",
			"count" : 3304,
			"avg_ms" : 129.65799031477,
			"min_ms" : 100,
			"max_ms" : 371
		}
	],
	"ok" : 1
}
```

### Гистограммы по времени выполнения запросов.

Этот пример по-сложнее: нужно посчитать гистограмму по времени выполнения запросов. Для построения гистограммы я выбрал шаг в 50 миллисекунд. Что бы проще было группировать, я сначала получаю остаток от деления($mod) millis на 50, а потом вычитаю($subtract) полученное значение из millis. В псевдокоде это просто:

millis = millis - (millis % 50)

В итоге после первого шага агрегации получается следующее:
```js
> db.system.profile.aggregate([{$project: {'ms':{'$subtract':['$millis',{$mod:['$millis', 50]}]}}}, {$limit:5}])

// result
{
	"result" : [
		{
			"ms" : 100
		},
		{
			"ms" : 350
		},
		{
			"ms" : 300
		},
		{
			"ms" : 100
		},
		{
			"ms" : 100
		}
	],
	"ok" : 1
}
```


Осталось только сгруппировать данные по ms и подсчитать количество:
```js
db.system.profile.aggregate([{$project: {'ms':{'$subtract':['$millis',{$mod:['$millis', 50]}]}}}, {$group:{_id:'$ms', sum:{$sum:1}}}, {$sort:{_id:1}}]) 

// result
{ 
	"result" : [ 
		{ 
			"_id" : 100, 
			"sum" : 2993 
		}, 
		{ 
			"_id" : 150, 
			"sum" : 524 
		}, 
...
		{ 
			"_id" : 3600, 
			"sum" : 1 
		}, 
		{ 
			"_id" : 3650, 
			"sum" : 2 
		} 
	], 
	"ok" : 1 
} 
```
С помощью одного такого запроса мы можем быстро понять распределение запросов по времени выполнения.




## References:
* http://amezhenin.github.io/mongodb/mongodb-profiling-part-1.html
* http://amezhenin.github.io/mongodb/mongodb-profiling-part-2.html
* https://github.com/jsmarkus/the-little-mongodb-book/blob/master/ru/mongodb.markdown