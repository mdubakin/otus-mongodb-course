# Lesson 11. Replication & Sharding. Homework.

### Table of contents:
  - [Задание.](#задание)
  - [Выполнение.](#выполнение)
    - [Настройка кластера.](#настройка-кластера)
    - [Проблемы при настройке.](#проблемы-при-настройке)
      - [1. Прослушивается внутренний интерфейс, а не внешний.](#1-прослушивается-внутренний-интерфейс-а-не-внешний)
      - [2. Не удается подключиться к MongoDB с локальной машины.](#2-не-удается-подключиться-к-mongodb-с-локальной-машины)
      - [3. Нехватка ресурсов.](#3-нехватка-ресурсов)
    - [Проверка отказоустойчивости.](#проверка-отказоустойчивости)
      - [1. Отключение одного secondary хоста на одном шарде.](#1-отключение-одного-secondary-хоста-на-одном-шарде)
      - [2. Отключение одной зоны доступности.](#2-отключение-одной-зоны-доступности)
      - [3. Отключение целого шарда.](#3-отключение-целого-шарда)
    - [Реализация PITR backup.](#реализация-pitr-backup)
   
# Задание.
```
В результате выполнения ДЗ вы настроите реплицирование и шардирование, аутентификацию в кластере и проверите отказоустойчивость.

Необходимо:
  - [x] построить шардированный кластер из 3 кластерных нод( по 3 инстанса с репликацией) и с кластером конфига(3 инстанса);
  - [x] добавить балансировку, нагрузить данными, выбрать хороший ключ шардирования, посмотреть как данные перебалансируются между шардами;
  - [x] настроить аутентификацию и многоролевой доступ;
  - [x] поронять разные инстансы, посмотреть, что будет происходить, поднять обратно. Описать что произошло.
  - [] * реализовать бэкап шардированного кластера.
  - [] ** реализовать бэкап шардированного кластера на ванильной Монго, желательно под нагрузкой и проверить восстановление из бэкапа.
  - [] *** реализовать PITR бэкап шардированного кластера на ванильной Монго, желательно под нагрузкой и проверить восстановление из бэкапа.
```
# Выполнение. 

## Настройка кластера.

Поднял шардированный кластер по примеру из практики:
----------------------------------------------------------------------------------------------------------------
| Hostname | RS1 (port 27011) | RS2 (port 27021) | RS3 (port 27031) | RScfg (port 27001) | Mongos (port 27000) |
|----------|------------------|------------------|------------------|--------------------|---------------------|
| mongo1   |  Primary         | Secondary        |  Secondary       | Primary            |  -                  |
| mongo2   |  Secondary       | Primary          |  Secondary       | Secondary          |  -                  |
| mongo3   |  Secondary       | Secondary        |  Primary         | Secondary          |  +                  |
| mongo4   |  -               | -                |  -               | -                  |  +                  |
----------------------------------------------------------------------------------------------------------------
Таблица 1. Распределение ролей шардированного кластера.

Конфигурации серверов:
----------------------------------------------------------------------------
| Hostname | vCPU | Memory | Internal IP | External IP    | Zone           |
|----------|------|--------|-------------|----------------|----------------|
| mongo1   |  2   | 8 Gb   | 10.156.0.3  | 35.198.148.37  | europe-west3-a |
| mongo2   |  2   | 8 Gb   | 10.156.0.4  | 34.159.194.240 | europe-west3-a |
| mongo3   |  2   | 8 Gb   | 10.156.0.5  | 35.246.222.0   | europe-west3-a |
| mongo4   |  2   | 8 Gb   | 10.156.0.2  | 35.234.88.74   | europe-west3-a |
----------------------------------------------------------------------------
Таблица 2. Технические характеристики серверов в кластере.

Шардировал коллекцию `values` по ключу `stock_symbol`:
----------------------------------------------------------------------------
![Рисунок 1. Распределение чанков по шардам кластера.](https://i.ibb.co/6Z8vq03/image.png)

Рисунок 1. Распределение чанков по шардам кластера.

## Проблемы при настройке.

### 1. Прослушивается внутренний интерфейс, а не внешний.
При выполнении команды запуска `mongod` из файла практики возникала проблема, что в этом случае mongod "слушает" сетевые интерфейсы `localhost` и внутренний сетевой интерфейс (`10.156.0.0/24`), следовательно подключиться без VPN к базе данных не получалось.

Команда:
```bash
for i in {1..3}; do gcloud compute ssh mongo$i --command='hostname; mongod --auth --keyFile /home/mongo/mongo-security/keyfile --configsvr --bind_ip localhost,${hostname} --dbpath /home/mongo/dbc1 --port 27001 --replSet RScfg --fork --logpath /home/mongo/dbc1/dbc1.log --pidfilepath /home/mongo/dbc1/dbc1.pid' & done;
```

Решил эту проблему с помощью ключа `--bind_ip_all`, с помощью которого mongod стал прослушивать все интерфейсы (`0.0.0.0`)

Решение:
```bash
for i in {1..3}; do gcloud compute ssh mongo$i --command='hostname; mongod --auth --keyFile /home/mongo/mongo-security/keyfile --configsvr --bind_ip_all --dbpath /home/mongo/dbc1 --port 27001 --replSet RScfg --fork --logpath /home/mongo/dbc1/dbc1.log --pidfilepath /home/mongo/dbc1/dbc1.pid' & done;
```

### 2. Не удается подключиться к MongoDB с локальной машины.
После того, как я успешно запустил MongoDB с доступом извне, я столкнулся с проблемой подключения с локальной машины. Стало ясно, что дело в Firewall GCP.

Решил эту проблему путем создания правила в GCP, где я разрешил доступ извне ко всех портам с определенного IP-адреса (моего роутера).

### 3. Нехватка ресурсов.
После успешной настройки шардированного кластера я добавил туда данные и включил шардированние коллекции, сразу после этого почти все мои сервера повисли, а через некоторое время `RS3` вышел из строя, так как завершились процессы mongod из-за OOM Killer (предположительно).

До конца эффективно эту проблему решить не удалось, так как в GCP имеется начальная квота на CPU. Я остановил все инстансы и изменил тип с `e2-medium` на `e2-standard-2`, тем самым увеличив Memory в 2 раза.


## Проверка отказоустойчивости.
### 1. Отключение одного secondary хоста на одном шарде.
Сымитируем ситуацию отказа mongo2 secondary хоста RS1. Посмотрим за состоянием шадрированного кластера и попробуем прочитать данные.

1. Убьем mongod RS2 на сервере mongo2.
```js
RS1 > rs.status()
...
{
    _id: 1,
    name: 'mongo2:27011',
    health: 0,
    state: 8,
    stateStr: '(not reachable/healthy)',
    ...
}
```
2. Проверим возможность чтения из mongos.
```js
db.values.findOne()
{ _id: ObjectId("4d094f58c96767d7a0099d49"),
  exchange: 'NASDAQ',
  stock_symbol: 'AACC',
  date: '2008-03-07',
  open: 8.4,
  high: 8.75,
  low: 8.08,
  close: 8.55,
  volume: 275800,
  'adj close': 8.55 }
```
3. Вернем участника RS в живое состояние.
```js
RS1 > rs.status()
...
{
      _id: 1,
      name: 'mongo2:27011',
      health: 1,
      state: 2,
      stateStr: 'SECONDARY',
      ...
}
```

Итог: никаких проблем не возникло.

### 2. Отключение одной зоны доступности.
Сымитируем отключение одной зоны доступности, что привело к отключению мастеров (в нашем случае мастера развернуты в одной зоне доступности). Посмотрим за состоянием шадрированного кластера и попробуем прочитать данные.

1. Убьем master процессы mongod (RS1 = mongo1, RS2 = mongo2, RS3 = mongo3, RScfg = mongo1).
```js
RS1 > rs.status()
...
{
    _id: 0,
    name: 'mongo1:27011',
    health: 0,
    state: 8,
    stateStr: '(not reachable/healthy)',
    ...
}
```
Так же и в других ReplicaSet.
2. Проверим возможность чтения из mongos.
```js
db.values.findOne()
{ _id: ObjectId("4d094f58c96767d7a0099d49"),
  exchange: 'NASDAQ',
  stock_symbol: 'AACC',
  date: '2008-03-07',
  open: 8.4,
  high: 8.75,
  low: 8.08,
  close: 8.55,
  volume: 275800,
  'adj close': 8.55 }
```
3. Вернем участников RS в живое состояние.
```js
RS1 > rs.status()
...
{
      _id: 0,
      name: 'mongo1:27011',
      health: 1,
      state: 1,
      stateStr: 'PRIMARY',
      ...
}
```
Так же и в других ReplicaSet.
Стоит заметить, что если приоритет у нод в ReplicaSet одинаковый, то ожившая нода станет `Secondary`, а если стоял более высокий приоритет (как в случае с мастером RS1 на примере), то он снова станет `Primary`.

Итог: так как запись происходит только в мастер, то на время выбора мастера запись была невозможна. В итоге все заработало отработки консенсуса.

### 3. Отключение целого шарда.
Сымитируем ситуацию, когда весь шард становится недоступным (довольно редкий случай). Посмотрим за состоянием шадрированного кластера и попробуем прочитать данные.

1. Убьем все процессы mongod в RS1.
2. Проверим возможность чтения из mongos. Получаем ошибку:
```js
Encountered non-retryable error during query :: caused by :: Could not find host matching read preference { mode: "primary" } for set RS1
```
3. Вернем участников RS1 в живое состояние.
После восстановления RS1, стала возможным чтение и работа с шард. кластером.

Итог: при отключении одного шарда, перестает быть доступна запись и чтение всего шардированного кластера.

## Реализация PITR backup.
Шаг 1. Создание роли и пользователя в каждом RS.
```js
use admin
db.getSiblingDB("admin").createRole({ "role": "pbmAnyAction",
      "privileges": [
         { "resource": { "anyResource": true },
           "actions": [ "anyAction" ]
         }
      ],
      "roles": []
   });

db.getSiblingDB("admin").createUser({user: "pbmuser",
       "pwd": "secretpwd",
       "roles" : [
          { "db" : "admin", "role" : "readWrite", "collection": "" },
          { "db" : "admin", "role" : "backup" },
          { "db" : "admin", "role" : "clusterMonitor" },
          { "db" : "admin", "role" : "restore" },
          { "db" : "admin", "role" : "pbmAnyAction" }
       ]
    });
```

Шаг 2. Создать конфигурацию хранилища резервных копий.
Создаем и распространяем по всем нодам файл `pbm_config.yaml`
```yaml
storage:
  type: filesystem
  filesystem:
    path: /home/mongo/backups
```

Шаг 3. Запуск pbm-agent на всех нодах с включенным PITR.
```bash
pbm config --set pitr.enabled=true --file /home/aeugene/pbm_config.yaml \
--mongodb-uri "mongodb://****:****@localhost:27001/?authSource=admin&replicaSet=RScfg"
```

Шаг 4. Создаем backup.
```bash
pbm backup --compression=gzip
```
```bash
# pbm list
Backup snapshots:
  2022-01-29T15:20:42Z [complete: 2022-01-29T15:21:01]

PITR <on>:
```
PITR пока не появился, так как PITR создается каждые 10 минут.

Спустя 10 минут PITR-бэкап появился:
```bash
# pbm list
Backup snapshots:
  2022-01-29T15:20:42Z [complete: 2022-01-29T15:21:01]
  2022-01-29T15:47:05Z [complete: 2022-01-29T15:47:22]

PITR <on>:
  2022-01-29T15:21:02 - 2022-01-29T15:46:58
  2022-01-29T15:47:23 - 2022-01-29T16:45:58
```

Шаг 5. Удаляем коллекцию values.
Перед этим получим кол-во документов: 
```js
db.values.count()
4308303
```
Дропаем коллекцию:
```js
db.values.drop()
```
```js
db.values.count()
0
```

Шаг 6. Восстанавливаем данные.
Для восстановления данных, требуется отключить PITR.
```bash
for i in {1..3}; do gcloud compute ssh mongo$i --command="export PBM_MONGODB_URI='mongodb://pbmuser:***@localhost:27021/?authSource=admin&replicaSet=RScfg' && pbm config --set pitr.enabled=false" & done;
```
Восстанавливаем данные:
```bash
# требуется запустить на всех нодах
pbm restore 2022-01-29T15:47:05Z
```
```js
db.values.count()
4308303
```
Включаем обратно PITR на всех pbm-agent.
```bash
for i in {1..3}; do gcloud compute ssh mongo$i --command="export PBM_MONGODB_URI='mongodb://pbmuser:***@localhost:27021/?authSource=admin&replicaSet=RScfg' && pbm config --set pitr.enabled=true" & done;
```